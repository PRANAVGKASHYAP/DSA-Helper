{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a1a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial graph for all the agents\n"
     ]
    }
   ],
   "source": [
    "print(\"Trial graph for all the agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5007d",
   "metadata": {},
   "source": [
    "IMPORTING ALL THE REQUIRED PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfefc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8d17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkgno\\AppData\\Local\\Temp\\ipykernel_35524\\2486430593.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  import research_agent  , question_generator_agent , coding_agent , research_2\n"
     ]
    }
   ],
   "source": [
    "import research_agent  , question_generator_agent , coding_agent , research_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5323c86",
   "metadata": {},
   "source": [
    "CREATING THE GRAPH STATE ---> this is a shared data source in the entire graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fbe98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic:str # this is the main concept/algorithm/idea to research and frame questions on \n",
    "    research_json: dict # this will hold the json output from the research agent\n",
    "    question: dict # this is formatted data of the question that is generated by the question generator agent\n",
    "    solution: dict # this field is the answer to the problem , need to be filled optionally\n",
    "    human_feedback: str # this field is ment to add human feedback , mostly regarding to the question "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d261c",
   "metadata": {},
   "source": [
    "Creating a simple researcher node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145189a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_2 import JsonOutput , ResearchAgent\n",
    "\n",
    "\n",
    "def research_node(state : State):\n",
    "    \"\"\" this is a node for the researcher agent , to perform web search and curate\n",
    "    information on the requested topic\"\"\"\n",
    "\n",
    "    \n",
    "    print(\"********* Researcher node is running**********\")\n",
    "    topic = state['topic']\n",
    "\n",
    "    # create the research object and call the functions\n",
    "    research_agent = ResearchAgent()\n",
    "    output = research_agent.search(topic)\n",
    "    print(f\"the final output got from the research agent  is -->\\n\\n {output}\" )\n",
    "\n",
    "    # the final step is to add the data or any changes to the graph state\n",
    "    return {\"research_json\": output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0729b8e",
   "metadata": {},
   "source": [
    "Creating the question creator node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98bf5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_crafter_node(state : State):\n",
    "    \"\"\"  This node is to be used for crafting the question from the research json object\n",
    "    Here the key insights from the research will be transformed into a question after analyzing it and taking into consideration all the key technical details.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"*********** Question Crafter node is running ****************\")\n",
    "\n",
    "    #1. take the research json object from the graph state\n",
    "    research_json = state['research_json'] # this is the knowledge packet for creating the question\n",
    "\n",
    "    # serialize this data\n",
    "    import json\n",
    "    from question_generator import QuestionGenerator\n",
    "    question_creator = QuestionGenerator()\n",
    "    research_string_data = json.dumps(research_json)\n",
    "    generated_question = question_creator.generate_question(research_string_data)\n",
    "    print(f\"\\n The question generated by the agent is : \\n\\n {generated_question}\")\n",
    "    #update the graph state with this question\n",
    "    return {\"question\": generated_question.model_dump()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc260bfe",
   "metadata": {},
   "source": [
    "Creating the coder agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e0660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_solver(state:State):\n",
    "    \"\"\" This node is to be used for solving the question that is generated by the question generator agent\n",
    "    This will involve analyzing the question and generating a solution based on the constraints given and generating the most optimal solution.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"*********** Question Solver node is running ****************\")\n",
    "\n",
    "    #1. take the research json object from the graph state\n",
    "    question = state['question'] \n",
    "    # this data needs to be converted into the pydantic model \n",
    "    from question_generator_agent import CodeQuestion # this is the data model\n",
    "    import coding_agent\n",
    "    formatted_question = CodeQuestion(**question)\n",
    "    #now give this to the llm to solve\n",
    "    solution = coding_agent.solve_question(formatted_question)\n",
    "    print(f\"\\n The solution generated by the agent is : \\n\\n {solution}\")\n",
    "    \n",
    "    return {\"solution\" : solution }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e0e0aa",
   "metadata": {},
   "source": [
    "CREATING A HUMAN IN THE GRAPH NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc553671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This node is ment to add human intput in the graph \n",
    "\n",
    "def human_review(state: State):\n",
    "    \"\"\" this is to take teh human feed back on the question generated \"\"\"\n",
    "\n",
    "\n",
    "    print(\"*********** Human review node is running ****************\")\n",
    "\n",
    "    #1. print the current question \n",
    "    print(f\"The current generated question is : \\n\\n {state['question']}\")\n",
    "    #2. take the human input\n",
    "    feedback = input(\"Please provide your feedback on the question generated : \")\n",
    "    \n",
    "    return {\"human_feedback\": feedback.lower()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422c5bc",
   "metadata": {},
   "source": [
    "Creating a router node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324c51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    \"\"\" this is a router node to decide the flow of the graph based on the human feedback \"\"\"\n",
    "    \n",
    "    print(\"*********** Router node is running ****************\")\n",
    "\n",
    "    feedback = state.get(\"human_feedback\", \"\")\n",
    "    \n",
    "    # CHECK IF THE FEEDBACK IS POSITIVE OR NOT \n",
    "    if feedback == \"yes\":\n",
    "        return \"solver\"\n",
    "    elif feedback == \"no\":\n",
    "        return \"question_crafter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13cbbe",
   "metadata": {},
   "source": [
    "CREATING THE GRAPH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8bda2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the stateGraph of lang graph to create a 3 node graph to connect all the agents\n",
    "from langgraph.graph import START , END , StateGraph\n",
    "\n",
    "#1. initialize an empty graph with the state object\n",
    "graph = StateGraph(State) # State is the shared data between all the nodes\n",
    "\n",
    "#2. add nodes to the graph\n",
    "graph.add_node(\"Researcher\" , research_node)\n",
    "graph.add_node(\"Question Generator\" , question_crafter_node)\n",
    "\n",
    "# adding one more node in the graph to take human feed back\n",
    "graph.add_node(\"Human Review\" , human_review) \n",
    "graph.add_node(\"Question Solver\" , question_solver)\n",
    "\n",
    "#3. add the edges \n",
    "graph.add_edge(START , \"Researcher\")\n",
    "graph.add_edge(\"Researcher\" , \"Question Generator\")\n",
    "graph.add_edge(\"Question Generator\" , \"Human Review\") \n",
    "#graph.add_edge(\"Question Generator\" , \"Question Solver\")\n",
    "graph.add_edge(\"Question Solver\" , END)\n",
    "\n",
    "# adding conditional edges\n",
    "graph.add_conditional_edges(\n",
    "    \"Human Review\",\n",
    "    router,\n",
    "    {\n",
    "        \"solver\": \"Question Solver\", # this is for yes \n",
    "        \"question_crafter\": \"Question Generator\" # this is for no case\n",
    "    }\n",
    ")\n",
    "\n",
    "#graph.add_edge(\"Researcher\" , END)\n",
    "\n",
    "complete_dsa_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5629a0",
   "metadata": {},
   "source": [
    "graph design 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9d7ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the graph\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# 2. Add all the nodes\n",
    "graph.add_node(\"Researcher\", research_node)\n",
    "graph.add_node(\"Question Generator\", question_crafter_node)\n",
    "graph.add_node(\"Human Review\", human_review)\n",
    "graph.add_node(\"Question Solver\", question_solver)\n",
    "\n",
    "# 3. Define the edges\n",
    "graph.set_entry_point(\"Researcher\")\n",
    "graph.add_edge(\"Researcher\", \"Question Generator\")\n",
    "graph.add_edge(\"Question Generator\", \"Human Review\")\n",
    "\n",
    "# The conditional edge now only chooses between solving or regenerating\n",
    "graph.add_conditional_edges(\n",
    "    \"Human Review\",\n",
    "    router,\n",
    "    {\n",
    "        \"solver\": \"Question Solver\",\n",
    "        \"question_crafter\": \"Question Generator\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# The ONLY path to the end is from the Question Solver\n",
    "graph.add_edge(\"Question Solver\", END)\n",
    "\n",
    "# 4. Compile the graph\n",
    "complete_dsa_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38ddf3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-----------+      \n",
      "    | __start__ |      \n",
      "    +-----------+      \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "    +------------+     \n",
      "    | Researcher |     \n",
      "    +------------+     \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+--------------------+ \n",
      "| Question Generator | \n",
      "+--------------------+ \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "   +--------------+    \n",
      "   | Human Review |    \n",
      "   +--------------+    \n",
      "           .           \n",
      "           .           \n",
      "           .           \n",
      "  +-----------------+  \n",
      "  | Question Solver |  \n",
      "  +-----------------+  \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "      +---------+      \n",
      "      | __end__ |      \n",
      "      +---------+      \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the graph \n",
    "\n",
    "print(complete_dsa_agent.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921be38",
   "metadata": {},
   "source": [
    "TESTING THE GRAPH WORK FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d80f0b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Invoking the LangGraph Application...\n",
      "********* Researcher node is running**********\n",
      "Output of gemini api is : \n",
      "['The article \"Top 10 Most Asked Binary Search Interview Questions\" by Kirti Arora discusses binary search as a fundamental algorithm with O(log n) time complexity, crucial for technical interviews. It outlines ten common interview questions, providing problem statements and Java code solutions for each.\\n\\nThe questions covered include:\\n1.  **Basic Binary Search:** Implementing iterative or recursive approaches to find a target in a sorted array.\\n2.  **Find the First and Last Position of an Element in a Sorted Array:** Modifying binary search to locate both the starting and ending indices of a target value.\\n3.  **Search Insert Position:** Determining the index of a target in a sorted array, or where it would be inserted if not found.\\n4.  **Find the Kth Smallest Element in a Sorted Matrix:** Utilizing a max-priority queue to find the kth smallest element in a row and column-sorted matrix.\\n5.  **Square Root of a Number:** Computing the integer square root of a given number using binary search to narrow down the range.\\n6.  **Search in Rotated Sorted Array:** Adapting binary search to handle arrays rotated at an unknown pivot, by identifying the sorted half.\\n7.  **Find Minimum in Rotated Sorted Array:** Applying binary search to locate the pivot point, which reveals the minimum element in a rotated sorted array.\\n8.  **Find Peak Element:** Modifying binary search to find an element greater than its neighbors, by checking neighbors and moving towards the peak.\\n9.  **Find the Duplicate Number:** Solving this without modifying the array or using extra space, often done using the Floyd\\'s cycle-finding algorithm (though the problem is listed under binary search, the provided solution uses a two-pointer approach similar to linked list cycle detection).\\n10. **Median of Two Sorted Arrays:** Combining binary search with partitioning logic to efficiently find the median of two sorted arrays.\\n\\nThe article emphasizes that understanding these problems and efficiently applying solutions is key to mastering binary search for interviews. The provided snippet mentions the sliding window technique, which is a powerful approach for array and string problems, but it\\'s listed under \"Recommended from Medium\" and not directly part of the \"Top 10 Binary Search Questions\" list itself.', 'The article \"Binary Search Algorithm in Java: Implementation and Key Concepts\" from Index.dev provides a detailed guide to the binary search algorithm, a fundamental search technique in computer science known for its efficiency. The article highlights its importance, working mechanism, implementation strategies, performance considerations, real-world applications, strengths, weaknesses, and common pitfalls, particularly within the context of Java.\\n\\n**What is Binary Search Algorithm?**\\nBinary search is a fast search algorithm that works on sorted arrays. It operates on a \"divide and conquer\" principle, continually halving the search space until the target value is found or the search space is exhausted. This approach significantly reduces the time complexity compared to linear search.\\n\\n**Why is it Important?**\\nBinary search is crucial for several reasons:\\n*   **Ease of Implementation:** It\\'s relatively simple to understand and implement.\\n*   **High Efficiency:** Especially for large datasets, it offers a logarithmic time complexity (O(log n)), making it highly efficient for fast data processing.\\n*   **Scalability:** Its logarithmic time complexity ensures efficient performance even with millions or billions of elements.\\n\\n**How Does it Work?**\\nThe algorithm begins by examining the middle element of a sorted array.\\n1.  If the middle element matches the target, the search is successful.\\n2.  If the target is smaller than the middle element, the search continues in the left half of the array.\\n3.  If the target is larger, the search continues in the right half.\\nThis process of halving the search space repeats until the target is found or no elements remain in the search space.\\n\\n**Implementation Strategies in Java**\\nBinary search can be implemented in two primary ways:\\n*   **Iterative Approach:** Uses a `while` loop to repeatedly narrow down the search space. It maintains `low`, `high`, and `mid` indices. The `mid` index is calculated as `low + (high - low) / 2` to prevent integer overflow.\\n    *   **Explanation:** `low` tracks the start, `high` tracks the end, and `mid` is the current middle. If `arr[mid]` equals the target, `mid` is returned. If `target` is greater, `low` becomes `mid + 1`. If `target` is smaller, `high` becomes `mid - 1`. The loop continues as long as `low <= high`.\\n*   **Recursive Approach:** Involves a function that calls itself with updated search boundaries.\\n    *   **Explanation:** The base case is when `low > high`, indicating the target isn\\'t found, returning -1. Otherwise, `mid` is calculated. If `arr[mid]` equals the target, `mid` is returned. If `arr[mid]` is less than the target, the function recursively calls itself on the right half (`mid + 1`, `high`). If `arr[mid]` is greater, it calls itself on the left half (`low`, `mid - 1`).\\n\\n**Choosing the Right Approach:**\\nThe choice often depends on programmer preference and coding conventions. Iterative implementations might be slightly faster due to the absence of function call overhead. Recursive solutions can be more concise and elegant, and some languages offer tail-call optimization to mitigate performance differences.\\n\\n**Performance Considerations:**\\nBoth iterative and recursive implementations have a time complexity of O(log n), which is significantly better than linear search\\'s O(n). Iterative solutions typically have slightly better performance due to less overhead from function calls.\\n\\n**Strengths and Weaknesses:**\\n\\n**Advantages:**\\n*   **Logarithmic Time Complexity (O(log n)):** Offers significantly faster searches, especially for large datasets (e.g., 20 comparisons for a million elements vs. a million for linear search).\\n*   **Space Efficiency:** Requires minimal additional space (O(1)) as it operates directly on the input array.\\n*   **Predictable Performance:** Its worst-case complexity is well-defined, making it suitable for real-time systems.\\n*   **Versatility:** Serves as a foundation for more complex algorithms like interpolation search.\\n*   **Error Detection:** Can indirectly help detect unsorted data if the target isn\\'t found, implying a sorting irregularity.\\n\\n**Disadvantages:**\\n*   **Requires Sorted Data:** This is a strict prerequisite; binary search fails on unsorted arrays, often requiring a pre-sorting step which adds overhead.\\n*   **Memory and Recursion Overhead:** Recursive implementations can lead to stack overflow for very deep searches due to call stack usage. Iterative approaches, while longer, avoid this.\\n*   **Caching Considerations:** The random access pattern might be less beneficial for CPU caching compared to linear search in some scenarios.\\n*   **Error-Prone Logic:** Careful handling is needed for choosing the middle element, duplicate values, and boundary conditions to avoid off-by-one errors or infinite loops.\\n*   **Limited Functionality:** Primarily designed for finding specific items; less effective for tasks like counting all elements within a range.\\n\\n**Common Mistakes and Pitfalls:**\\n1.  **Integer Overflow:** Calculating `mid = (low + high) / 2` can cause overflow if `low + high` exceeds the `int` limit. The safer approach is `mid = low + (high - low) / 2`.\\n2.  **Unsorted Arrays:** Forgetting to ensure the array is sorted before applying binary search.\\n3.  **Off-by-One Errors:** Incorrect comparison operators (e.g., `<` instead of `<=`) or boundary updates can lead to infinite loops or wrong results.\\n4.  **Not Handling \"Target Not Found\":** Failing to return an appropriate indicator (like -1) when the target element is not present.\\n5.  **Choosing Recursion Over Iteration (and vice-versa) Unwisely:** While recursion can be elegant, iterative might be better for performance-critical tasks or to avoid stack overflow with very large datasets.\\n\\n**Beyond the Fundamentals (Variations and Extensions):**\\nThe article also touches on advanced concepts like:\\n*   **Finding First/Last Occurrence:** Modifying binary search to locate the first or last instance of a duplicate element.\\n*   **Finding Elements Around the Target:** Adapting it to find elements closest to the target or the insertion point for a new element.\\n*   **Optimizing Performance:** Strategies include pre-sorting, using primitive data types, loop unrolling (with caution), and hybrid approaches.\\n\\n**Real-World Applications:**\\n*   **Database Management Systems (DBMS):** Used for quick record searches by leveraging indexes.\\n*   **In-Memory Data Structures:** Efficiently accessing large datasets like stock tickers or network routing tables.\\n*   **Machine Learning and AI:** Fast searching in sorted datasets for training and classification, such as in k-Nearest Neighbors (kNN) algorithms.\\n\\n**Variations and Extensions to Other Data Structures:**\\nWhile typically associated with arrays, binary search concepts can be applied to:\\n*   **Sorted Linked Lists:** Requires maintaining node counts and traversing to find the middle, but still aims for O(log n) time.\\n*   **Balanced Search Trees (AVL, Red-Black Trees):** Binary search naturally translates to tree traversal, maintaining O(log n) due to self-balancing properties.\\n*   **B-Trees:** Optimized for disk-stored data, where binary search can be used within nodes to find the correct child pointer, achieving O(log n) performance for large datasets.\\n\\nIn summary, binary search is a powerful and efficient algorithm for sorted data, crucial for any developer\\'s toolkit, but requires careful implementation and consideration of its constraints and nuances for optimal performance.', '\\nThe Lenovo.com glossary entry defines binary search as an efficient algorithm for finding a target element in a **sorted array** by repeatedly dividing the search interval in half. This process eliminates half of the remaining elements with each comparison until the target is found or the interval is empty. It boasts a time complexity of O(log n), making it particularly effective for large datasets where efficiency is critical.\\n\\nTechnically, binary search works by comparing the target value with the middle element of the array. If they match, the search is successful; if the target is less than the middle, the search continues in the lower half; otherwise, it proceeds in the upper half. This divide-and-conquer approach can be implemented both iteratively and recursively, with recursive implementations often lauded for their concise and elegant code.\\n\\nWhile commonly associated with arrays due to efficient random access, binary search can be adapted to other sorted data structures like trees or lists. Key advantages include its O(log n) efficiency and relative simplicity of implementation. However, it strictly requires the data to be sorted, and applying it to an unsorted array necessitates a prior sorting step, adding to the overall complexity. Handling duplicates typically involves finding the first occurrence, with modifications needed for finding the last occurrence or counting. For very small datasets, the overhead of sorting might make simpler linear search more appropriate. The article also notes that binary search can work with non-numeric and floating-point data, though precision issues must be considered for the latter, and overflow scenarios need appropriate handling. Applying binary search to an empty array will result in failure.']\n",
      "\n",
      "\n",
      "The final output of the model is:\n",
      " title='Comprehensive Guide to Binary Search' description='Binary search is an efficient, fast search algorithm that operates on sorted arrays using a \"divide and conquer\" principle, repeatedly halving the search space until the target element is found or the search interval is empty, achieving an O(log n) time complexity.' algorithm_steps=[{}, {}, {}, {}, {}, {}, {}] coding_implementations=[{}, {}] specialized_implementations=[{}, {}, {}, {}, {}, {}, {}, {}, {}] benefits=[{}, {}, {}, {}, {}, {}] , and the type of it is :\n",
      "<class 'research_2.JsonOutput'>\n",
      "the final output got from the research agent  is -->\n",
      "\n",
      " {\n",
      "  \"title\": \"Comprehensive Guide to Binary Search\",\n",
      "  \"description\": \"Binary search is an efficient, fast search algorithm that operates on sorted arrays using a \\\"divide and conquer\\\" principle, repeatedly halving the search space until the target element is found or the search interval is empty, achieving an O(log n) time complexity.\",\n",
      "  \"algorithm_steps\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ],\n",
      "  \"coding_implementations\": [\n",
      "    {},\n",
      "    {}\n",
      "  ],\n",
      "  \"specialized_implementations\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ],\n",
      "  \"benefits\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ]\n",
      "}\n",
      "*********** Question Crafter node is running ****************\n",
      "\n",
      " The question generated by the agent is : \n",
      "\n",
      " title='Vent Chain Re-alignment' description=\"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\" test_cases=[TestCase(input='[3, 4, 5, 1, 2]', expected_output='1', explanation=\"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1, 2, 3, 4, 5]', expected_output='-1', explanation='The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'), TestCase(input='[5, 1, 2, 3, 4]', expected_output='1', explanation=\"'1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1]', expected_output='-1', explanation='A single element array is considered sorted; there is no predecessor to compare against.'), TestCase(input='[2, 1]', expected_output='1', explanation=\"'1' is less than '2'. This is the anomaly point.\"), TestCase(input='[7, 8, 9, 1, 2, 3, 4, 5, 6]', expected_output='1', explanation=\"'1' is less than '9'. This is the anomaly point.\")] time_complexity='O(log N)' input_format='readings: list[int]' output_format='int' constraints=['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']\n",
      "*********** Human review node is running ****************\n",
      "The current generated question is : \n",
      "\n",
      " {'title': 'Vent Chain Re-alignment', 'description': \"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\", 'test_cases': [{'input': '[3, 4, 5, 1, 2]', 'expected_output': '1', 'explanation': \"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1, 2, 3, 4, 5]', 'expected_output': '-1', 'explanation': 'The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'}, {'input': '[5, 1, 2, 3, 4]', 'expected_output': '1', 'explanation': \"'1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1]', 'expected_output': '-1', 'explanation': 'A single element array is considered sorted; there is no predecessor to compare against.'}, {'input': '[2, 1]', 'expected_output': '1', 'explanation': \"'1' is less than '2'. This is the anomaly point.\"}, {'input': '[7, 8, 9, 1, 2, 3, 4, 5, 6]', 'expected_output': '1', 'explanation': \"'1' is less than '9'. This is the anomaly point.\"}], 'time_complexity': 'O(log N)', 'input_format': 'readings: list[int]', 'output_format': 'int', 'constraints': ['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']}\n",
      "*********** Router node is running ****************\n",
      "*********** Question Crafter node is running ****************\n",
      "\n",
      " The question generated by the agent is : \n",
      "\n",
      " title='Vent Chain Re-alignment' description=\"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\" test_cases=[TestCase(input='[3, 4, 5, 1, 2]', expected_output='1', explanation=\"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1, 2, 3, 4, 5]', expected_output='-1', explanation='The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'), TestCase(input='[5, 1, 2, 3, 4]', expected_output='1', explanation=\"'1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1]', expected_output='-1', explanation='A single element array is considered sorted; there is no predecessor to compare against.'), TestCase(input='[2, 1]', expected_output='1', explanation=\"'1' is less than '2'. This is the anomaly point.\"), TestCase(input='[7, 8, 9, 1, 2, 3, 4, 5, 6]', expected_output='1', explanation=\"'1' is less than '9'. This is the anomaly point.\")] time_complexity='O(log N)' input_format='readings: list[int]' output_format='int' constraints=['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']\n",
      "*********** Human review node is running ****************\n",
      "The current generated question is : \n",
      "\n",
      " {'title': 'Vent Chain Re-alignment', 'description': \"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\", 'test_cases': [{'input': '[3, 4, 5, 1, 2]', 'expected_output': '1', 'explanation': \"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1, 2, 3, 4, 5]', 'expected_output': '-1', 'explanation': 'The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'}, {'input': '[5, 1, 2, 3, 4]', 'expected_output': '1', 'explanation': \"'1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1]', 'expected_output': '-1', 'explanation': 'A single element array is considered sorted; there is no predecessor to compare against.'}, {'input': '[2, 1]', 'expected_output': '1', 'explanation': \"'1' is less than '2'. This is the anomaly point.\"}, {'input': '[7, 8, 9, 1, 2, 3, 4, 5, 6]', 'expected_output': '1', 'explanation': \"'1' is less than '9'. This is the anomaly point.\"}], 'time_complexity': 'O(log N)', 'input_format': 'readings: list[int]', 'output_format': 'int', 'constraints': ['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']}\n",
      "*********** Router node is running ****************\n",
      "*********** Question Crafter node is running ****************\n",
      "\n",
      " The question generated by the agent is : \n",
      "\n",
      " title='Vent Chain Re-alignment' description=\"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\" test_cases=[TestCase(input='[3, 4, 5, 1, 2]', expected_output='1', explanation=\"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1, 2, 3, 4, 5]', expected_output='-1', explanation='The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'), TestCase(input='[5, 1, 2, 3, 4]', expected_output='1', explanation=\"'1' is less than '5'. This is the first such anomaly point.\"), TestCase(input='[1]', expected_output='-1', explanation='A single element array is considered sorted; there is no predecessor to compare against.'), TestCase(input='[2, 1]', expected_output='1', explanation=\"'1' is less than '2'. This is the anomaly point.\"), TestCase(input='[7, 8, 9, 1, 2, 3, 4, 5, 6]', expected_output='1', explanation=\"'1' is less than '9'. This is the anomaly point.\")] time_complexity='O(log N)' input_format='readings: list[int]' output_format='int' constraints=['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']\n",
      "*********** Human review node is running ****************\n",
      "The current generated question is : \n",
      "\n",
      " {'title': 'Vent Chain Re-alignment', 'description': \"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' â€“ the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\", 'test_cases': [{'input': '[3, 4, 5, 1, 2]', 'expected_output': '1', 'explanation': \"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1, 2, 3, 4, 5]', 'expected_output': '-1', 'explanation': 'The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.'}, {'input': '[5, 1, 2, 3, 4]', 'expected_output': '1', 'explanation': \"'1' is less than '5'. This is the first such anomaly point.\"}, {'input': '[1]', 'expected_output': '-1', 'explanation': 'A single element array is considered sorted; there is no predecessor to compare against.'}, {'input': '[2, 1]', 'expected_output': '1', 'explanation': \"'1' is less than '2'. This is the anomaly point.\"}, {'input': '[7, 8, 9, 1, 2, 3, 4, 5, 6]', 'expected_output': '1', 'explanation': \"'1' is less than '9'. This is the anomaly point.\"}], 'time_complexity': 'O(log N)', 'input_format': 'readings: list[int]', 'output_format': 'int', 'constraints': ['1 <= len(readings) <= 10^5', '-10^9 <= readings[i] <= 10^9', 'All elements in `readings` are unique.']}\n",
      "*********** Router node is running ****************\n",
      "*********** Question Solver node is running ****************\n",
      "the code and explanation generated by the llm is : \n",
      "\n",
      "\n",
      " thinking=\"The problem statement is clear and concise. It's a simple algorithmic problem that requires a straightforward approach. I will start by identifying the anomaly point by comparing each element to its predecessor. If an element is lower than its predecessor, it means that the sensor chain was re-spooled at that point. The time complexity of this solution is O(log N) because we only need to compare each element to its predecessor once.\" code_complexity='Time: O(log n), Space: O(1)' code='def find_anomaly_point(readings):\\n\\n    # Initialize the anomaly point to -1\\n    anomaly_point = -1\\n\\n    # Iterate over the readings and compare each element to its predecessor\\n    for i in range(len(readings) - 1):\\n        if readings[i] > readings[i + 1]:\\n            anomaly_point = i\\n            break\\n\\n    # Return the anomaly point or -1 if no such drop exists\\n    return anomaly_point'\n",
      "the generated code is :\n",
      "\n",
      "def find_anomaly_point(readings):\n",
      "\n",
      "    # Initialize the anomaly point to -1\n",
      "    anomaly_point = -1\n",
      "\n",
      "    # Iterate over the readings and compare each element to its predecessor\n",
      "    for i in range(len(readings) - 1):\n",
      "        if readings[i] > readings[i + 1]:\n",
      "            anomaly_point = i\n",
      "            break\n",
      "\n",
      "    # Return the anomaly point or -1 if no such drop exists\n",
      "    return anomaly_point\n",
      "\n",
      " The solution generated by the agent is : \n",
      "\n",
      " def find_anomaly_point(readings):\n",
      "\n",
      "    # Initialize the anomaly point to -1\n",
      "    anomaly_point = -1\n",
      "\n",
      "    # Iterate over the readings and compare each element to its predecessor\n",
      "    for i in range(len(readings) - 1):\n",
      "        if readings[i] > readings[i + 1]:\n",
      "            anomaly_point = i\n",
      "            break\n",
      "\n",
      "    # Return the anomaly point or -1 if no such drop exists\n",
      "    return anomaly_point\n",
      "\n",
      "--- âœ… Graph Execution Complete ---\n",
      "\n",
      "\n",
      "--- Generated Question ---\n",
      "{\n",
      "  \"title\": \"Vent Chain Re-alignment\",\n",
      "  \"description\": \"A deep-sea exploration vessel is deploying a chain of specialized environmental sensors along a thermal vent. Each sensor measures a unique environmental parameter, and due to the nature of the vent, these readings are expected to be monotonically increasing along the chain. However, during deployment, a critical error occurred: the entire sensor chain was inadvertently 're-spooled' from an arbitrary point, effectively rotating the sequence of readings. The data stream you receive is a single array representing these sensor readings. Your task is to identify the 'Anomaly Point' \\u2013 the *value* of the first sensor reading that is *lower* than its immediate predecessor in the *given* sequence. This point signifies where the re-spooling occurred and is crucial for re-aligning the data. If the sensor chain is perfectly sorted (i.e., no such drop exists within the sequence), you should report `-1`.\",\n",
      "  \"test_cases\": [\n",
      "    {\n",
      "      \"input\": \"[3, 4, 5, 1, 2]\",\n",
      "      \"expected_output\": \"1\",\n",
      "      \"explanation\": \"The sequence '3, 4, 5' is increasing, then '1' is less than '5'. This is the first such anomaly point.\"\n",
      "    },\n",
      "    {\n",
      "      \"input\": \"[1, 2, 3, 4, 5]\",\n",
      "      \"expected_output\": \"-1\",\n",
      "      \"explanation\": \"The sequence is perfectly sorted; no sensor reading is lower than its immediate predecessor.\"\n",
      "    },\n",
      "    {\n",
      "      \"input\": \"[5, 1, 2, 3, 4]\",\n",
      "      \"expected_output\": \"1\",\n",
      "      \"explanation\": \"'1' is less than '5'. This is the first such anomaly point.\"\n",
      "    },\n",
      "    {\n",
      "      \"input\": \"[1]\",\n",
      "      \"expected_output\": \"-1\",\n",
      "      \"explanation\": \"A single element array is considered sorted; there is no predecessor to compare against.\"\n",
      "    },\n",
      "    {\n",
      "      \"input\": \"[2, 1]\",\n",
      "      \"expected_output\": \"1\",\n",
      "      \"explanation\": \"'1' is less than '2'. This is the anomaly point.\"\n",
      "    },\n",
      "    {\n",
      "      \"input\": \"[7, 8, 9, 1, 2, 3, 4, 5, 6]\",\n",
      "      \"expected_output\": \"1\",\n",
      "      \"explanation\": \"'1' is less than '9'. This is the anomaly point.\"\n",
      "    }\n",
      "  ],\n",
      "  \"time_complexity\": \"O(log N)\",\n",
      "  \"input_format\": \"readings: list[int]\",\n",
      "  \"output_format\": \"int\",\n",
      "  \"constraints\": [\n",
      "    \"1 <= len(readings) <= 10^5\",\n",
      "    \"-10^9 <= readings[i] <= 10^9\",\n",
      "    \"All elements in `readings` are unique.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "--- Generated Solution ---\n",
      "\"def find_anomaly_point(readings):\\n\\n    # Initialize the anomaly point to -1\\n    anomaly_point = -1\\n\\n    # Iterate over the readings and compare each element to its predecessor\\n    for i in range(len(readings) - 1):\\n        if readings[i] > readings[i + 1]:\\n            anomaly_point = i\\n            break\\n\\n    # Return the anomaly point or -1 if no such drop exists\\n    return anomaly_point\"\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL TEST BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "\n",
    "    # Define the initial state to kick off the graph\n",
    "    initial_state = {\n",
    "        \"topic\": \"key concepts on binary search algorithm and most common questions on it\"\n",
    "    }\n",
    "\n",
    "    print(\"ðŸš€ Invoking the LangGraph Application...\")\n",
    "    \n",
    "    # The .invoke() method runs the graph from the entry point to the end.\n",
    "    final_state = complete_dsa_agent.invoke(initial_state)\n",
    "\n",
    "    print(\"\\n--- âœ… Graph Execution Complete ---\")\n",
    "    \n",
    "    # The final state contains all the accumulated data.\n",
    "    # We can now access the generated question and its solution.\n",
    "    \n",
    "    print(\"\\n\\n--- Generated Question ---\")\n",
    "    print(json.dumps(final_state['question'], indent=2))\n",
    "    \n",
    "    print(\"\\n\\n--- Generated Solution ---\")\n",
    "    print(json.dumps(final_state['solution'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3de52179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Comprehensive Guide to Binary Search\",\n",
      "  \"description\": \"Binary search is an efficient algorithm for finding a specific target element within a sorted array or list. It works by repeatedly dividing the search interval in half, eliminating half of the remaining elements with each comparison until the target is found or the search interval becomes empty.\",\n",
      "  \"algorithm_steps\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ],\n",
      "  \"coding_implementations\": [\n",
      "    {}\n",
      "  ],\n",
      "  \"specialized_implementations\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ],\n",
      "  \"benefits\": [\n",
      "    {},\n",
      "    {},\n",
      "    {},\n",
      "    {}\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(final_state['research_json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefd723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "websearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
