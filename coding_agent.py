# this is a coding agent and is used to solve and explain any coding question 

from langchain_core.pydantic_v1 import BaseModel, Field
from typing import List
from langchain_ollama import OllamaLLM , ChatOllama
from question_generator_agent import CodeQuestion, TestCase
# define pydantic classes to structure the input and output

#1. define an output class as a class
class Solution(BaseModel):
    """ This is a class to guide the llm to generate output in the 
    required structure and format to process it further"""

    thinking : str = Field(..., description="This is the detailed thought process of the solution , this needs to be very detailed and step by step")
    code_complexity :str = Field(..., description="This is the time and space complexity of the code solution , this needs to be explained in an understandable and concise manner")
    code :str = Field(..., description="This is the final code solution , this needs to be in python and should be well commented and easy to understand")


# class CodeQuestion(BaseModel):
#     """ This class is to give a structure for the entire question that will be generated by the llm"""

#     title: str = Field(..., description="The title of the question , this meeds to be a little creative or new")
#     description: str = Field(..., description="A detailed description of the question ,  this will act as the problme statement , this needs to have clear technical language ane needs to be 1-2 paras long")
#     test_cases: list[TestCase] = Field(..., description="A list of test cases for the question")
#     time_complexity : str = Field(..., description="The expected time complexity of the optimal solution for the question")
#     input_format: str = Field(..., description="A description of the function's input format.")
#     output_format: str = Field(..., description="A description of the function's expected return format.")
#     constraints: list[str] = Field(..., description="A list of constraints on the input data.")

def create_prompt(problem:CodeQuestion):
    """this is a function that takes the pydantic object from the previous agent and frames a coding question"""

    problem_str = f"""
    Title: {problem.title}
    Problem Statement: {problem.description}
    Input Format: {problem.input_format}
    Output Format: {problem.output_format}
    Constraints: {', '.join(problem.constraints)}
    Expected Time Complexity: {problem.time_complexity}
    """
    # now this is all the information needed by code llama model to generate a solution
    prompt = f"""
    **Persona:** You are a world-class competitive programmer and senior software engineer at a top tech company. Your solutions are not only correct but also optimally efficient, clean, and exceptionally well-explained. You think step-by-step before writing a single line of code.

    **Your Task:** You will receive a coding problem. Your task is to solve it by providing a complete and detailed answer that conforms to the required output schema. You are required to
    give the optimal solution only, for your reference you will be given the expected time complexity also as part of the question. Your generated code needs to be well documented i.e must contain
    comments whenever necessary for increasing readability and understanding.

    ---
    **Coding Problem:**
    {problem_str}
    ---

    
    **Output Instructions:**
    You must provide a response with three distinct sections.
    1.  **Thought Process:** First, explain your step-by-step thinking. How did you deconstruct the problem? What core algorithm did you identify? **Crucially, your thought process and code MUST directly address the specific constraints and challenges mentioned in the problem statement, such as the integer overflow potential.**
    2.  **Complexity Analysis:** State the final time and space complexity of your solution (e.g., Time: O(log n), Space: O(1)) and briefly justify it.
    3.  **Code Solution:** Provide the complete, commented code solution in Python. The code must be clean, correct, and implement the logic described in your thought process
        
    """

    return prompt

def solve_question(question:CodeQuestion):
    # this is the function where codellama is invoked
    prompt = create_prompt(question)
    llm = ChatOllama(model="codellama:7b", temperature=0.1)
    structured_llm = llm.with_structured_output(Solution)
    result = structured_llm.invoke(prompt)
    print(f"the code and explanation generated by the llm is : \n\n\n {result}")

    with open('solution.txt' , "w") as f:
        f.write(f"the code and explanation generated by the llm is : \n\n\n {result}")

    code = result.code
    print(f"the generated code is :\n\n{code}")
    return code

# creating a mock code question object
# --- 3. Create a Mock `CodeQuestion` Object for Testing ---

mock_problem = CodeQuestion(
    title="Galactic Archive Search",
    description="The Grand Galactic Library maintains a massive, sorted archive of star charts. The archive is so large that its indices are 64-bit integers. A new star chart has been added, but its entry might be corrupted. Your task is to find the index of this new chart, identified by a specific `target_id`. Because the archive is vast, a standard binary search using `mid = (low + high) / 2` might cause an integer overflow when `low` and `high` are very large numbers. You must implement a binary search that avoids this specific overflow issue.",
    input_format="A sorted list of integers `charts` representing star chart IDs, and an integer `target_id`.",
    output_format="An integer representing the index of the `target_id`. If the target is not found, return -1.",
    constraints=[
        "The list `charts` can contain up to 2^31 - 1 elements.",
        "Chart IDs are positive integers."
    ],
    test_cases=[
        TestCase(input="charts = [1, 3, 5, 7, 9], target_id = 5", expected_output="2", explanation="The target is in the middle of the array."),
        TestCase(input="charts = [1, 2, 3, 4, 5], target_id = 6", expected_output="-1", explanation="The target is not present in the array.")
    ],
    time_complexity="O(log n)"
)

# class CodeQuestion(BaseModel):
#     """ This class is to give a structure for the entire question that will be generated by the llm"""

#     title: str = Field(..., description="The title of the question , this meeds to be a little creative or new")
#     description: str = Field(..., description="A detailed description of the question ,  this will act as the problme statement , this needs to have clear technical language ane needs to be 1-2 paras long")
#     test_cases: list[TestCase] = Field(..., description="A list of test cases for the question")
#     time_complexity : str = Field(..., description="The expected time complexity of the optimal solution for the question")
#     input_format: str = Field(..., description="A description of the function's input format.")
#     output_format: str = Field(..., description="A description of the function's expected return format.")
#     constraints: list[str] = Field(..., description="A list of constraints on the input data.")

# solve_question(mock_problem)
