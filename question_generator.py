# this is a file that has modified and structured code for generating question 

import json
from langchain.prompts import PromptTemplate
from langchain.output_parsers import JsonOutputToolsParser
#langchain_core.output_parsers.json.JsonOutputParser
from langchain_core.output_parsers.json import JsonOutputParser  
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_ollama import OllamaLLM
import os
from dotenv import load_dotenv
load_dotenv()

# using pydantic to structure teh llm output
from pydantic import BaseModel, ValidationError , Field

# define all the pydantic classes for teh llm structured output
class TestCase(BaseModel):
    """ this is a class that defines how each test case needs to be defined """
    input: str = Field(..., description="The input to the test case ,  this defined the input data that is given to the function")
    expected_output: str = Field(..., description="The expected output of the test case , this defined the data and its type or structure that needs to be outputted by the function ")
    explanation: str = Field(..., description="A brief explanation of why this is the expected output for the given input")

# now define the class for the entire question 
class CodeQuestion(BaseModel):
    """ This class is to give a structure for the entire question that will be generated by the llm"""

    title: str = Field(..., description="The title of the question , this needs to be a little creative or new")
    description: str = Field(..., description="A detailed description of the question ,  this will act as the problme statement , this needs to have clear technical language ane needs to be 1-2 paras long")
    test_cases: list[TestCase] = Field(..., description="A list of test cases for the question")
    time_complexity : str = Field(..., description="The expected time complexity of the optimal solution for the question")
    input_format: str = Field(..., description="A description of the function's input format.")
    output_format: str = Field(..., description="A description of the function's expected return format.")
    constraints: list[str] = Field(..., description="A list of constraints on the input data.")

class QuestionGenerator:

    llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key=os.getenv("GEMINI_API_KEY"),
    # other params...
    )

    structured_llm = llm.with_structured_output(CodeQuestion)

    def generate_question(self, json_string_data , prompt_enhancer=None):
        # in this function define a prompt and then call the gemini llm 

        from langchain_core.prompts import ChatPromptTemplate

        prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                (
                    "You are a world-class principal engineer and interview architect at a top-tier tech company. "
                    "Your responsibility is to design **elite-level, novel coding interview problems** that probe beyond memorization "
                    "and evaluate a candidate’s raw reasoning, abstraction, and adaptability.\n\n"

                    "**CRITICAL OUTPUT REQUIREMENTS:**\n"
                    "- You MUST produce output **strictly matching the provided Pydantic schema (CodeQuestion)**.\n"
                    "- All fields must be complete, detailed, and precise.\n"
                    "- Test cases must be diverse, non-trivial, and include edge cases.\n\n"

                    "**DESIGN GUIDELINES:**\n"
                    "1. **Narrative Obfuscation:** Wrap the core algorithmic idea in a real-world, creative scenario. "
                    "The underlying technique should be *hidden* and only discoverable through deep reasoning.\n"
                    "2. **Central Technical Twist:** Choose one of the `key-technical-considerations` in the JSON knowledge packet "
                    "and make it the heart of the problem. The twist should force the candidate to rethink or adapt a known technique.\n"
                    "3. **Avoid Obviousness:** Do NOT state or hint at the underlying algorithm’s name. "
                    "The challenge must feel fresh and original, never a textbook-style exercise.\n"
                    "4. **Enforce Adaptation:** The candidate must reconcile conflicting constraints, optimize within unusual rules, "
                    "or resolve edge cases that break standard implementations.\n"
                    "5. **No Trivial Patterns:** Reject overly common problems (e.g., Fibonacci, factorial, standard sorting). "
                    "Problems should feel unique, technically demanding, and realistic for high-stakes interviews.\n"
                    "6. **Complexity Awareness:** Clearly state the optimal expected time complexity and ensure "
                    "constraints guide the candidate towards that.\n"
                    "7. **Professional Polish:** Titles should sound intriguing but professional. "
                    "Descriptions must be written in precise, technical, interview-grade English."
                )
            ),
            (
                "user",
                (
                    "Here is the JSON knowledge packet:\n\n```json\n{json_data}\n```\n\n"
                    "{prompt_enhancer}"
                    "Now generate one **unique, technically sophisticated coding problem** following the above instructions."
                )
            ),
        ])


        chain = prompt | self.structured_llm

        gemini_response = chain.invoke(
        {
            "json_data": json_string_data,
            "prompt_enhancer": prompt_enhancer if prompt_enhancer else ""
        }
        )

        return gemini_response